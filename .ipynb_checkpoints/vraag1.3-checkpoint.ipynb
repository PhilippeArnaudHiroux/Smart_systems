{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0868a59-1c83-4f12-b254-967f55cf3a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\SmartSystems\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from numpy.random import randn\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b499034-2fb1-4625-898e-8e81214db99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/htx_weather.csv')\n",
    "data = data.dropna(axis=0)\n",
    "data['RainTodayFlag'] = data['rain_today'].apply(lambda x: 1 if x=='Yes' else 0)\n",
    "data['RainTomorrowFlag'] = data['rain_tomorrow'].apply(lambda x: 1 if x=='Yes' else 0)\n",
    "data = data.drop(['date', 'cloud9am', 'cloud3pm', 'rain_today', 'rain_tomorrow'], axis=1)\n",
    "data.replace('Blank', 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "202c654b-4197-4820-8ab3-5b8c36c35e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['min_temp', 'max_temp', 'rainfall', 'wind_speed9am', 'wind_speed3pm', 'humidity9am', 'humidity3pm', 'pressure9am', 'pressure3pm', 'temp9am', 'temp3pm', 'RainTodayFlag']\n",
    "label = ['RainTomorrowFlag']\n",
    "X = data[features]\n",
    "y = data[label] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e631c421-205e-4993-bc09-61fd6d5dd4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ruben\\AppData\\Local\\Temp\\ipykernel_14996\\902468889.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_true.fit(X_true_train,y_true_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Accuracy: 0.7992700729927007\n",
      "Base classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89       881\n",
      "           1       0.43      0.07      0.13       215\n",
      "\n",
      "    accuracy                           0.80      1096\n",
      "   macro avg       0.62      0.53      0.51      1096\n",
      "weighted avg       0.74      0.80      0.74      1096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_true_train, X_true_test, y_true_train, y_true_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "clf_true = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "clf_true.fit(X_true_train,y_true_train)\n",
    "\n",
    "y_true_pred=clf_true.predict(X_true_test)\n",
    "\n",
    "print(\"Base Accuracy:\",metrics.accuracy_score(y_true_test, y_true_pred))\n",
    "print(\"Base classification report:\",metrics.classification_report(y_true_test, y_true_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3e7a4778-f9aa-43d6-ada9-f21a7c0ae7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c7839816-f0b1-4d75-89df-ed41b5dd7454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    X = generator.predict(x_input)\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4e293b86-2d79-4673-8aef-87186eb0cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(n):\n",
    "    X = data.sample(n)\n",
    "    y = np.ones((n, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cebcfdc2-4244-4d50-9359-8cca47039efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(latent_dim, n_outputs=9):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15, activation='relu',  kernel_initializer='he_uniform', input_dim=latent_dim))\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9c5ccb77-5c70-4d2b-9520-48390867a1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 15)                165       \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 30)                480       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 9)                 279       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 924\n",
      "Trainable params: 924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator1 = define_generator(10, 9)\n",
    "generator1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f6a84844-3112-4847-9d32-1f6ae281acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(n_inputs=9):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(25, activation='relu', kernel_initializer='he_uniform', input_dim=n_inputs))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "89e1a917-6889-4364-9351-befbeec7605a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_39 (Dense)            (None, 25)                250       \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 50)                1300      \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,601\n",
      "Trainable params: 1,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator1 = define_discriminator(9)\n",
    "discriminator1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "23720666-76c8-4366-acdf-4c7485c5dd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c89e3660-4402-43b6-bff0-ba9c7a48bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(d_hist, g_hist):\n",
    "    # plot loss\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.plot(d_hist, label='d')\n",
    "    plt.plot(g_hist, label='gen')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b061c83e-a3de-44cd-9c9a-41dac004b641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, latent_dim, n_epochs=1000, n_batch=128, n_eval=200):\n",
    "    # determine half the size of one batch, for updating the  discriminator\n",
    "    half_batch = int(n_batch / 2)\n",
    "    d_history = []\n",
    "    g_history = []\n",
    "    # manually enumerate epochs\n",
    "    for epoch in range(n_epochs):\n",
    "    \n",
    "        # prepare real samples\n",
    "        x_real, y_real = generate_real_samples(half_batch)\n",
    "        # prepare fake examples\n",
    "        x_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        # update discriminator\n",
    "        d_loss_real, d_real_acc = d_model.train_on_batch(x_real, y_real)\n",
    "        d_loss_fake, d_fake_acc = d_model.train_on_batch(x_fake, y_fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        # prepare points in latent space as input for the generator\n",
    "        x_gan = generate_latent_points(latent_dim, n_batch)\n",
    "        # create inverted labels for the fake samples\n",
    "        y_gan = np.ones((n_batch, 1))\n",
    "        # update the generator via the discriminator's error\n",
    "        g_loss_fake = gan_model.train_on_batch(x_gan, y_gan)\n",
    "        #print('>%d, d1=%.3f, d2=%.3f d=%.3f g=%.3f' % (epoch+1, d_loss_real, d_loss_fake, d_loss,  g_loss_fake))\n",
    "        d_history.append(d_loss)\n",
    "        g_history.append(g_loss_fake)\n",
    "        #plot_history(d_history, g_history)\n",
    "        g_model.save('trained_generated_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "097d040f-8140-4819-8061-0c921b2df72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\SmartSystems\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:102\u001b[0m, in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 102\u001b[0m     spec \u001b[38;5;241m=\u001b[39m \u001b[43mtype_spec_from_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    104\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[0;32m    105\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\SmartSystems\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:485\u001b[0m, in \u001b[0;36mtype_spec_from_value\u001b[1;34m(element, use_fallback)\u001b[0m\n\u001b[0;32m    482\u001b[0m     logging\u001b[38;5;241m.\u001b[39mvlog(\n\u001b[0;32m    483\u001b[0m         \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to convert \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m to tensor: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, e))\n\u001b[1;32m--> 485\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not build a `TypeSpec` for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    486\u001b[0m     element,\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not build a `TypeSpec` for       min_temp  max_temp  rainfall wind_speed9am wind_speed3pm humidity9am  \\\n2416      80.0      97.0       0.0           6.0           7.0        70.0   \n608       79.0      90.0       0.0           7.0          13.0        74.0   \n3589      53.0      81.0       0.0           5.0           6.0        45.0   \n3225      38.0      60.0       0.0          14.0           5.0        48.0   \n2981      59.0      73.0       0.0           8.0           9.0        90.0   \n...        ...       ...       ...           ...           ...         ...   \n2365      76.0      91.0       0.0           5.0          12.0        72.0   \n189       75.0      87.0       0.8           3.0           8.0        76.0   \n336       42.0      56.0       0.0          17.0          21.0        50.0   \n2778      77.0      88.0       3.0           0.0           8.0        77.0   \n2199      37.0      43.0       0.0          14.0          12.0        89.0   \n\n     humidity3pm pressure9am pressure3pm temp9am temp3pm  RainTodayFlag  \\\n2416        36.0       29.98        29.9    88.0    96.0              0   \n608         72.0        29.9       29.82    85.0    85.0              0   \n3589        21.0       30.02       29.98    71.0    80.0              0   \n3225        44.0       30.36       30.21    50.0    60.0              0   \n2981        76.0       30.03       29.93    60.0    73.0              0   \n...          ...         ...         ...     ...     ...            ...   \n2365        59.0       30.11       30.05    84.0    90.0              0   \n189         74.0       29.99       29.94    84.0    84.0              1   \n336         30.0       30.48       30.44    46.0    55.0              0   \n2778        67.0       29.98       29.93    85.0    88.0              1   \n2199        93.0        30.4       30.37    39.0    38.0              0   \n\n      RainTomorrowFlag  \n2416                 0  \n608                  0  \n3589                 0  \n3225                 0  \n2981                 0  \n...                ...  \n2365                 0  \n189                  0  \n336                  0  \n2778                 0  \n2199                 1  \n\n[64 rows x 13 columns] with type DataFrame",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [68], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m gan_model \u001b[38;5;241m=\u001b[39m define_gan(generator, discriminator)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgan_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [67], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(g_model, d_model, gan_model, latent_dim, n_epochs, n_batch, n_eval)\u001b[0m\n\u001b[0;32m     12\u001b[0m x_fake, y_fake \u001b[38;5;241m=\u001b[39m generate_fake_samples(g_model, latent_dim, half_batch)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# update discriminator\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m d_loss_real, d_real_acc \u001b[38;5;241m=\u001b[39m \u001b[43md_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_real\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m d_loss_fake, d_fake_acc \u001b[38;5;241m=\u001b[39m d_model\u001b[38;5;241m.\u001b[39mtrain_on_batch(x_fake, y_fake)\n\u001b[0;32m     16\u001b[0m d_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39madd(d_loss_real, d_loss_fake)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\SmartSystems\\lib\\site-packages\\keras\\engine\\training.py:2140\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   2137\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[0;32m   2138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mscope(), \\\n\u001b[0;32m   2139\u001b[0m      training_utils\u001b[38;5;241m.\u001b[39mRespectCompiledTrainableState(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 2140\u001b[0m   iterator \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msingle_batch_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2141\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2142\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2143\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[0;32m   2144\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\SmartSystems\\lib\\site-packages\\keras\\engine\\data_adapter.py:1639\u001b[0m, in \u001b[0;36msingle_batch_iterator\u001b[1;34m(strategy, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1636\u001b[0m   data \u001b[38;5;241m=\u001b[39m (x, y, sample_weight)\n\u001b[0;32m   1638\u001b[0m _check_data_cardinality(data)\n\u001b[1;32m-> 1639\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_weight:\n\u001b[0;32m   1641\u001b[0m   dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(_make_class_weight_map_fn(class_weight))\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\SmartSystems\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:729\u001b[0m, in \u001b[0;36mDatasetV2.from_tensors\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_tensors\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    694\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a `Dataset` with a single element, comprising the given tensors.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \n\u001b[0;32m    696\u001b[0m \u001b[38;5;124;03m  `from_tensors` produces a dataset containing only a single element. To slice\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 729\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\SmartSystems\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4531\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[1;34m(self, element, name)\u001b[0m\n\u001b[0;32m   4529\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   4530\u001b[0m   \u001b[38;5;124;03m\"\"\"See `Dataset.from_tensors()` for details.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4531\u001b[0m   element \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4532\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_structure \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[0;32m   4533\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_structure, element)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\SmartSystems\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:107\u001b[0m, in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    102\u001b[0m     spec \u001b[38;5;241m=\u001b[39m type_spec_from_value(t, use_fallback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    104\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[0;32m    105\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m   normalized_components\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 107\u001b[0m       \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec, sparse_tensor\u001b[38;5;241m.\u001b[39mSparseTensorSpec):\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\SmartSystems\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\SmartSystems\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1640\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1631\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1632\u001b[0m           _add_error_prefix(\n\u001b[0;32m   1633\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1636\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1637\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m   1639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1640\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1643\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\SmartSystems\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:343\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    341\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    342\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[1;32m--> 343\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\SmartSystems\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    172\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\SmartSystems\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    278\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 279\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[0;32m    282\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\SmartSystems\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    303\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\SmartSystems\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "# size of the latent space\n",
    "latent_dim = 10\n",
    "# create the discriminator\n",
    "discriminator = define_discriminator()\n",
    "# create the generator\n",
    "generator = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(generator, discriminator)\n",
    "# train model\n",
    "train(generator, discriminator, gan_model, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5126f4-f86a-4884-8235-20a5bdaa3461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model =load_model('trained_generated_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044f046e-ec28-4a72-b04b-7d3ca2d4823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_points = generate_latent_points(10, 750)\n",
    "X = model.predict(latent_points)\n",
    "data_fake = pd.DataFrame(data=X,  columns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'])\n",
    "data_fake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5921bd9-6ec5-498a-82da-d8e3986b740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_mean = data_fake.Outcome.mean()\n",
    "data_fake['Outcome'] = data_fake['Outcome'] > outcome_mean\n",
    "data_fake[\"Outcome\"] = data_fake[\"Outcome\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d08c32a0-ba05-4634-8068-11b8295a513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "label = ['Outcome']\n",
    "X_fake_created = data_fake[features]\n",
    "y_fake_created = data_fake[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62d507b6-5485-4401-b818-fb5874c0ec8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ruben\\AppData\\Local\\Temp\\ipykernel_14996\\1381918943.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_fake.fit(X_fake_train,y_fake_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of fake data model: 0.9288888888888889\n",
      "Classification report of fake data model:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95       151\n",
      "           1       0.88      0.91      0.89        74\n",
      "\n",
      "    accuracy                           0.93       225\n",
      "   macro avg       0.92      0.92      0.92       225\n",
      "weighted avg       0.93      0.93      0.93       225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_fake_train, X_fake_test, y_fake_train, y_fake_test = train_test_split(X_fake_created, y_fake_created, test_size=0.30, random_state=42)\n",
    "clf_fake = RandomForestClassifier(n_estimators=100)\n",
    "clf_fake.fit(X_fake_train,y_fake_train)\n",
    "y_fake_pred=clf_fake.predict(X_fake_test)\n",
    "\n",
    "print(\"Accuracy of fake data model:\",metrics.accuracy_score(y_fake_test, y_fake_pred))\n",
    "print(\"Classification report of fake data model:\",metrics.classification_report(y_fake_test, y_fake_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c820ce9-d200-433a-8c06-fab7255bb09f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
